{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(bayes_theorem_notebook)=\n",
    "# Il teorema di Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il teorema di Bayes assume un ruolo fondamentale nell'interpretazione soggettivista della probabilità perchè descrive l'aggiornamento della credenza che si aveva nel verificarsi dell'ipotesi $H$ (quantificata con la probabilità assegnata all'ipotesi) in conseguenza del verificarsi dell'evidenza $E$.\n",
    "\n",
    "## Definizione\n",
    "\n",
    "```{admonition} Teorema\n",
    "Sia $(H_i)_{i\\geq 1}$ una partizione dell'evento certo $\\Omega$ e sia $E \\subseteq \\Omega$ un evento tale che $P(E) > 0$, allora, per $i = 1, \\dots, \\infty$:\n",
    "\n",
    "$$\n",
    "P(H_i \\mid E) = \\frac{P(E \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(H_j)P(E \\mid H_j)}.\n",
    "$$ (eq-bayes2)\n",
    "```\n",
    "\n",
    "L'eq. {eq}`eq-bayes2` contiene tre concetti fondamentali. I primi due distinguono il grado di fiducia precedente al verificarsi dell'evidenza $E$ da quello successivo al verificarsi dell'evidenza $E$. Pertanto, dati gli eventi $H, E \\subseteq \\Omega,$ si definisce\n",
    "\n",
    "- _probabilità a priori_, $P(H)$, la probabilità attribuita al verificarsi dell'ipotesi $H$ prima di sapere che si è verificato l'evento $E$;\n",
    "- _probabilità a posteriori_, $P(H \\mid E)$, la probabilità assegnata ad $H$ una volta che sia noto $E$, ovvero l'aggiornamento della probabilità a priori alla luce della nuova evidenza $E$.\n",
    "\n",
    "Il terzo concetto definisce la probabilità che ha l'evento $E$ di verificarsi quando è vera l'ipotesi $H$, ovvero la probabilità dell'evidenza in base all'ipotesi. Pertanto, dati gli eventi $H, E \\subseteq \\Omega$ si definisce\n",
    "\n",
    "- _verosimiglianza_ di $H$ dato $E$, $P(E \\mid H)$, la probabilità condizionata che si verifichi $E$, se è vera $H$.\n",
    "\n",
    "Si noti che, per il calcolo della quantità a denominatore dell'eq. {eq}`eq-bayes2`, si ricorre al teorema della probabilità assoluta.\n",
    "\n",
    "Per fare un esempio, consideriamo il seguente problema. Posta una partizione dell'evento certo $\\Omega$ in due soli eventi che chiamiamo ipotesi $H_1$ e $H_2$, supponiamo conosciute le probabilità a priori $P(H_1)$ e $P(H_2)$. Consideriamo un terzo evento $E \\subseteq \\Omega$ con probabilità non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilità condizionate $P(E \\mid H_1)$ e $P(E \\mid H_2)$. Supponendo che si sia verificato l'evento $E$, vogliamo conoscere le probabilità a posteriori delle ipotesi, ovvero $P(H_1 \\mid E)$ e $P(H_2 \\mid E)$. La figura rappresenta una partizione dell'evento certo in due eventi chiamati 'ipotesi'; l'evidenza $E$ è un sottoinsieme dello spazio campione.\n",
    "\n",
    "```{image} images/bayes_theorem.png\n",
    ":height: 230px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Per trovare la probabilità dell'ipotesi 1, ad esempio, alla luce dell'evidenza osservata, scriviamo:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(H_1 \\mid E) &= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\\n",
    "              &= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Sapendo che $E = (E \\cap H_1) \\cup (E \\cap H_2)$ e che $H_1$ e $H_2$ sono eventi disgiunti, ovvero $H_1 \\cap H_2 = \\emptyset$, ne segue che possiamo calcolare $P(E)$ utilizzando il teorema della probabilità totale:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(E) &= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\\n",
    "     &= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Sostituendo tale risultato nella formula precedente otteniamo:\n",
    "\n",
    "$$\n",
    "P(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n",
    "$$ (eq-bayes1)\n",
    "\n",
    "Un lettore attento si sarà reso conto che, in precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto il problema sulla mammografia e cancro al seno. In quel caso, le due ipotesi erano \"la malattia è presente\", che possiamo denotare con $M^+$, e \"la malattia è assente\", $M^-$. L'evidenza $E$ era costituita dal risultato positivo al test (denotiamo questo evento con $T^+$). Con questa notazione, possiamo scrivere l'eq. {eq}`eq-bayes1` nel modo seguente:\n",
    "\n",
    "$$\n",
    "P(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-)}.\n",
    "$$\n",
    "\n",
    "Inserendo i dati del problema nella formula precedente otteniamo\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n",
    "&= \\frac{9}{108} \\notag\\\\\n",
    "&\\approx 0.083.\\notag\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema di Bayes e valore predittivo di un test di laboratorio\n",
    "\n",
    "L'esercizio precedente illusta un uso importante del teorema di Bayes. Infatti, abbiamo visto sopra come il teorema di Bayes consente di calcolare la probabilità di malattia in caso di test positivo o la probabilità di assenza della malattia in caso di test negativo. Per ottenere questo risultato abbiamo bisogno delle seguenti informazioni: la prevalenza di una malattia, la sensibilità e la specificità di un test per la sua diagnosi. Esaminiamo più in dettaglio l'applicazione del teorema di Bayes in questo contesto.\n",
    "\n",
    "Si definisce come sensibilità la probabilità che il test dia un risultato positivo dato che la malattia è presente: $P(T^+ \\mid M^+)$. Una sensibilità del 100% significa che il test è positivo nel 100% dei malati, una sensibilità del 90% significa che il test è positivo nel 90% dei malati, e così via. \n",
    "\n",
    "Si definisce come specificità la probabilità che il test dia un risultato negativo dato che la malattia è assente: $P(T^- \\mid M^-)$. Una specificità del 100% significa che il\n",
    "test è negativo nel 100% dei sani, una specificità del 90% significa che il test è negativo nel 90%\n",
    "dei sani, e così via. \n",
    "\n",
    "Si definisce come prevalenza della malattia la probabilità che la malattia sia presente, $P^+$. Possiamo interpretare $P^+$ come la proporzione di individui malati, in un dato istante, nella popolazione. Una prevalenza del 5 per mille significa che il 5 per mille delle persone è affetto dalla malattia, e così via. \n",
    "\n",
    "|       | $T^+$                           | $T^-$                                | \n",
    "| :---: | :-----------------------------: | :----------------------------------: |\n",
    "| $M^+$ | $P(T^+ \\cap M^+)$ (sensibilità) | $P(T^- \\cap M^+)$ (1 - sensibilità)  |\n",
    "| $M^-$ | $P(T^+ \\cap M^-)$ (1 - specificità ) | $P(T^- \\cap M^-)$ (specificità) |\n",
    "\n",
    "Abbiamo visto che il teorema di Bayes può essere scritto nel modo seguente:\n",
    "\n",
    "$$\n",
    "P(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-)}.\n",
    "$$\n",
    "\n",
    "Usando la tabella precedente, il *valore predittivo del test positivo* è dunque:\n",
    "\n",
    "$$\n",
    "P(M^+ \\mid T^+) = \\frac{\\text{sensibilità} \\cdot \\text{prevalenza}}{\\text{sensibilità} \\cdot \\text{prevalenza} + (1 - \\text{sensibilità}) \\cdot (1 - \\text{prevalenza})}.\n",
    "$$\n",
    "\n",
    "In maniera corrispondente, il *valore predittivo del test negativo* è dato da\n",
    "\n",
    "$$\n",
    "P(M^- \\mid T^-  ) = \\frac{\\text{specificità} \\cdot (1 - \\text{prevalenza})}{\\text{specificità} \\cdot (1 - \\text{prevalenza}) + (1 - \\text{sensibilità}) \\cdot \\text{prevalenza}}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svolgiamo ora un esercizio in Python in cui calcoliamo il valore predittivo del test positivo e il valore predittivo del test negatico con i dati dell'esempio precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n",
    "    return (sens * prev) / (sens * prev + (1 - sens) * (1 - prev))\n",
    "\n",
    "\n",
    "def negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n",
    "    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(M+ | T+) = 0.083\n"
     ]
    }
   ],
   "source": [
    "sens = 0.9  # sensibilità\n",
    "spec = 0.9  # specificità\n",
    "prev = 0.01  # prevalenza\n",
    "\n",
    "res_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\n",
    "print(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(M- | T-) = 0.999\n"
     ]
    }
   ],
   "source": [
    "res_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\n",
    "print(f\"P(M- | T-) = {round(res_neg, 3)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggiornamento bayesiano\n",
    "\n",
    "Il teorema di Bayes rende esplicito il motivo per cui la probabilità non possa essere pensata come uno stato oggettivo, quanto piuttosto come un'inferenza soggettiva e condizionata. Il denominatore del membro di destra dell'eq. {eq}`eq-bayes2` è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: $P(H_i$) e $P(E \\mid H_i)$. La probabilità $P(H_i)$ è la probabilità *probabilità a priori* (*prior*) dell'ipotesi $H_i$ e rappresenta l'informazione che l'agente bayesiano possiede a proposito dell'ipotesi $H_i$. Diremo che $P(H_i)$ codifica il grado di fiducia che l'agente ripone in $H_i$ precedentemente al verificarsi dell'evidenza $E$. Nell'interpretazione bayesiana, $P(H_i)$ rappresenta un giudizio personale dell'agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. La probabilità condizionata $P(E \\mid H_i)$ rappresenta invece la verosimiglianza di $H_i$ dato $E$ e descrive la plausibilità che si verifichi l'evento $E$ se è vera l'ipotesi $H_i$. Il teorema di Bayes descrive la regola che l'agente deve seguire per aggiornare il suo grado di fiducia nell'ipotesi $H_i$ alla luce del verificarsi dell'evento $E$. La $P(H_i \\mid E)$ è chiamata probabilità a posteriori dato che rappresenta la nuova probabilità che l'agente assegna all'ipotesi $H_i$ affinché rimanga consistente con le nuove informazioni fornitegli da $E$.\n",
    "\n",
    "La probabilità a posteriori dipende sia dall'evidenza $E$, sia dalla conoscenza a priori dell'agente $P(H_i)$. È dunque chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità a priori, la quale a sua volta, per definizione, è un'assegnazione soggettiva. Ne segue pertanto che ogni probabilità deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell'agente.\n",
    "\n",
    "Dato che ogni assegnazione probabilistica rappresenta uno stato di conoscenza e che ciascun particolare stato di conoscenza è arbitrario, un accordo tra agenti diversi non è richiesto. Ciò nonostante, la teoria delle probabilità ci fornisce uno strumento che, alla luce di nuove evidenze, consente di aggiornare in un modo razionale il grado di fiducia che attribuiamo ad un'ipotesi, via via che nuove evidenze vengono raccolte, in modo tale da formulare un'ipotesi a posteriori la quale non è mai definitiva, ma può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama *aggiornamento bayesiano*.\n",
    "\n",
    "## Commenti e considerazioni finali\n",
    "\n",
    "La riflessione epistemologica contemporanea ha ampiamente messo in luce come la conoscenza non possa essere identificata con la certezza, ovvero con la garanzia razionale della verità. Da ciò deriva che qualunque giudizio deve necessariamente essere inteso come una decisione presa in condizioni d'incertezza. Stando così le cose, non si può più considerare la logica deduttiva, modellata sulle forme della dimostrazione matematica, come quella più adeguata al ragionamento scientifico. La ricerca scientifica ha invece bisogno di una *logica dell'incertezza* e questa viene fornita dalla teoria delle probabilità e, specialmente, da quello schema di inferenza noto come teorema di Bayes. È proprio in questi termini che può essere compresa quella rivoluzione metodologica contemporanea che, tra le altre cose, si è posta il problema di porre rimedio alla *crisi della replicabilità dei risultati della ricerca* {cite:p}`ioannidis2005most` che sta affligendo molti ambiti della ricerca scientifica, inclusa la psicologia. Per un approfondimento a questo tema rimando nuovamente al libro *Bernoulli's fallacy* di {cite:t}`clayton2021bernoulli`.\n",
    "\n",
    "In questo capitolo abbiamo descritto il teorema di Bayes facendo riferimento alle variabili casuali discrete. Il caso discreto, tuttavia, nonostante la sua apparente semplicità matematica, è il più contro-intuitivo. Risulta più intuitivo pensare al teorema di Bayes facendo riferimento alle variabili casuali continue. Questo sarà l'oggetto del capitolo {ref}`bayes-workflow-notebook`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c300c63927c1d487b2df0ca7f55d9699efd42c18a65d5b05a5383e492fa5764c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
