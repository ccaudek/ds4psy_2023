{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(bayes_theorem_notebook)=\n",
    "# Il teorema di Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il teorema di Bayes svolge un ruolo fondamentale nell'interpretazione soggettiva della probabilità in quanto descrive l'aggiornamento della credenza che si ha sulla probabilità del verificarsi dell'ipotesi $H$ in seguito alla presenza di un'evidenza $E$. In altre parole, il teorema di Bayes permette di quantificare la probabilità dell'ipotesi $H$ dopo aver considerato l'evidenza $E$.\n",
    "\n",
    "## Definizione\n",
    "\n",
    "```{admonition} Teorema\n",
    "Sia $(H_i)_{i\\geq 1}$ una partizione dell'evento certo $\\Omega$ e sia $E \\subseteq \\Omega$ un evento tale che $P(E) > 0$, allora, per $i = 1, \\dots, \\infty$:\n",
    "\n",
    "$$\n",
    "P(H_i \\mid E) = \\frac{P(E \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(H_j)P(E \\mid H_j)}.\n",
    "$$ (eq-bayes2)\n",
    "```\n",
    "\n",
    "Si possono identificare tre concetti fondamentali all'interno dell'eq. {eq}`eq-bayes2`. I primi due distinguono la misura di fiducia che si ha precedentemente al verificarsi dell'evidenza $E$ rispetto a quella che si ha successivamente al verificarsi dell'evidenza $E$. Pertanto, considerando gli eventi $H, E \\subseteq \\Omega$:\n",
    "\n",
    "- probabilità a priori, $P(H)$, rappresenta la probabilità assegnata all'ipotesi $H$ prima di conoscere l'evidenza $E$;\n",
    "- probabilità a posteriori, $P(H \\mid E)$, rappresenta l'aggiornamento della probabilità a priori al verificarsi dell'evidenza $E$.\n",
    "\n",
    "Il terzo concetto definisce la probabilità dell'evidenza $E$ quando l'ipotesi $H$ è vera, ovvero la probabilità dell'evidenza in base all'ipotesi. Quindi, dati gli eventi $H, E \\subseteq \\Omega$:\n",
    "\n",
    "- verosimiglianza di $H$ dato $E$, $P(E \\mid H)$, rappresenta la probabilità condizionata dell'evidenza $E$ data l'ipotesi $H$.\n",
    "\n",
    "Si osservi che per il calcolo del denominatore dell'eq. {eq}`eq-bayes2` si fa uso del teorema della probabilità totale. Il teorema di Bayes è di fondamentale importanza nell'interpretazione soggettivista della probabilità, poiché descrive l'aggiornamento della credenza nell'ipotesi $H$ (quantificata dalla probabilità assegnata all'ipotesi) in seguito al verificarsi dell'evidenza $E$.\n",
    "\n",
    "Per fare un esempio, consideriamo il seguente problema. Posta una partizione dell'evento certo $\\Omega$ in due soli eventi che chiamiamo ipotesi $H_1$ e $H_2$, supponiamo conosciute le probabilità a priori $P(H_1)$ e $P(H_2)$. Consideriamo un terzo evento $E \\subseteq \\Omega$ con probabilità non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilità condizionate $P(E \\mid H_1)$ e $P(E \\mid H_2)$. Supponendo che si sia verificato l'evento $E$, vogliamo conoscere le probabilità a posteriori delle ipotesi, ovvero $P(H_1 \\mid E)$ e $P(H_2 \\mid E)$. La figura rappresenta una partizione dell'evento certo in due eventi chiamati 'ipotesi'; l'evidenza $E$ è un sottoinsieme dello spazio campione.\n",
    "\n",
    "```{image} images/bayes_theorem.png\n",
    ":height: 230px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Per trovare la probabilità dell'ipotesi 1, ad esempio, alla luce dell'evidenza osservata, scriviamo:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(H_1 \\mid E) &= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\\n",
    "              &= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Sapendo che $E = (E \\cap H_1) \\cup (E \\cap H_2)$ e che $H_1$ e $H_2$ sono eventi disgiunti, ovvero $H_1 \\cap H_2 = \\emptyset$, ne segue che possiamo calcolare $P(E)$ utilizzando il teorema della probabilità totale:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(E) &= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\\n",
    "     &= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Sostituendo tale risultato nella formula precedente otteniamo:\n",
    "\n",
    "$$\n",
    "P(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n",
    "$$ (eq-bayes1)\n",
    "\n",
    "Un lettore attento si sarà reso conto che, in precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto il problema sulla mammografia e cancro al seno. In quel caso, le due ipotesi erano \"la malattia è presente\", che possiamo denotare con $M^+$, e \"la malattia è assente\", $M^-$. L'evidenza $E$ era costituita dal risultato positivo al test (denotiamo questo evento con $T^+$). Con questa notazione, possiamo scrivere l'eq. {eq}`eq-bayes1` nel modo seguente:\n",
    "\n",
    "$$\n",
    "P(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-)}.\n",
    "$$\n",
    "\n",
    "Inserendo i dati del problema nella formula precedente otteniamo\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n",
    "&= \\frac{9}{108} \\notag\\\\\n",
    "&\\approx 0.083.\\notag\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema di Bayes e valore predittivo di un test di laboratorio\n",
    "\n",
    "L'esercizio precedente illusta un uso importante del teorema di Bayes. Infatti, abbiamo visto sopra come il teorema di Bayes consente di calcolare la probabilità di malattia in caso di test positivo o la probabilità di assenza della malattia in caso di test negativo. Per ottenere questo risultato abbiamo bisogno delle seguenti informazioni: la prevalenza di una malattia, la sensibilità e la specificità di un test per la sua diagnosi. Esaminiamo più in dettaglio l'applicazione del teorema di Bayes in questo contesto.\n",
    "\n",
    "<br />\n",
    "\n",
    "```{image} images/bayes_theorem_2x.png\n",
    ":height: 320px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "<br />\n",
    "\n",
    "Si definisce come sensibilità la probabilità che il test dia un risultato positivo dato che la malattia è presente: $P(T^+ \\mid M^+)$. Una sensibilità del 100% significa che il test è positivo nel 100% dei malati, una sensibilità del 90% significa che il test è positivo nel 90% dei malati, e così via. \n",
    "\n",
    "Si definisce come specificità la probabilità che il test dia un risultato negativo dato che la malattia è assente: $P(T^- \\mid M^-)$. Una specificità del 100% significa che il\n",
    "test è negativo nel 100% dei sani, una specificità del 90% significa che il test è negativo nel 90%\n",
    "dei sani, e così via. \n",
    "\n",
    "Si definisce come prevalenza della malattia la probabilità che la malattia sia presente, $P^+$. Possiamo interpretare $P^+$ come la proporzione di individui malati, in un dato istante, nella popolazione. Una prevalenza del 5 per mille significa che il 5 per mille delle persone è affetto dalla malattia, e così via. \n",
    "\n",
    "|       | $T^+$                           | $T^-$                                | \n",
    "| :---: | :-----------------------------: | :----------------------------------: |\n",
    "| $M^+$ | $P(T^+ \\cap M^+)$ (sensibilità) | $P(T^- \\cap M^+)$ (1 - sensibilità)  |\n",
    "| $M^-$ | $P(T^+ \\cap M^-)$ (1 - specificità ) | $P(T^- \\cap M^-)$ (specificità) |\n",
    "\n",
    "Abbiamo visto che il teorema di Bayes può essere scritto nel modo seguente:\n",
    "\n",
    "$$\n",
    "P(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-)}.\n",
    "$$\n",
    "\n",
    "Usando la tabella precedente, il *valore predittivo del test positivo* è dunque:\n",
    "\n",
    "$$\n",
    "P(M^+ \\mid T^+) = \\frac{\\text{sensibilità} \\cdot \\text{prevalenza}}{\\text{sensibilità} \\cdot \\text{prevalenza} + (1 - \\text{sensibilità}) \\cdot (1 - \\text{prevalenza})}.\n",
    "$$\n",
    "\n",
    "In maniera corrispondente, il *valore predittivo del test negativo* è dato da\n",
    "\n",
    "$$\n",
    "P(M^- \\mid T^-  ) = \\frac{\\text{specificità} \\cdot (1 - \\text{prevalenza})}{\\text{specificità} \\cdot (1 - \\text{prevalenza}) + (1 - \\text{sensibilità}) \\cdot \\text{prevalenza}}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svolgiamo ora un esercizio in Python in cui calcoliamo il valore predittivo del test positivo e il valore predittivo del test negatico con i dati dell'esempio precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n",
    "    return (sens * prev) / (sens * prev + (1 - sens) * (1 - prev))\n",
    "\n",
    "\n",
    "def negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n",
    "    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(M+ | T+) = 0.083\n"
     ]
    }
   ],
   "source": [
    "sens = 0.9  # sensibilità\n",
    "spec = 0.9  # specificità\n",
    "prev = 0.01  # prevalenza\n",
    "\n",
    "res_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\n",
    "print(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(M- | T-) = 0.999\n"
     ]
    }
   ],
   "source": [
    "res_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\n",
    "print(f\"P(M- | T-) = {round(res_neg, 3)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggiornamento bayesiano\n",
    "\n",
    "Il teorema di Bayes esplicita il fatto che la probabilità non può essere considerata come uno stato oggettivo ma come un'inferenza soggettiva e condizionata. Nel numeratore dell'eq. {eq}`eq-bayes2` compaiono due quantità: $P(H_i)$ e $P(E \\mid H_i)$. La probabilità a priori $P(H_i)$ rappresenta l'informazione che l'agente bayesiano possiede a proposito dell'ipotesi $H_i$, ovvero il grado di fiducia che l'agente ripone in $H_i$ prima di conoscere l'evidenza $E$. L'agente bayesiano utilizza la probabilità a priori e la verosimiglianza $P(E \\mid H_i)$ per calcolare la probabilità a posteriori $P(H_i \\mid E)$, ovvero la nuova probabilità che l'agente assegna all'ipotesi $H_i$ alla luce dell'evidenza $E$.\n",
    "\n",
    "È importante notare che la probabilità a posteriori dipende sia dall'evidenza $E$ sia dalla conoscenza a priori dell'agente $P(H_i)$, il che significa che non ha senso parlare di una probabilità oggettiva. La probabilità a priori è un giudizio personale dell'agente e non esistono criteri esterni che possano determinare se tale giudizio sia corretto o meno. Pertanto, ogni probabilità deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell'agente.\n",
    "\n",
    "Poiché ogni assegnazione probabilistica rappresenta uno stato di conoscenza che è arbitrario, non è necessario che gli agenti abbiano lo stesso accordo. Tuttavia, la teoria delle probabilità fornisce uno strumento che consente di aggiornare in modo razionale il grado di fiducia che attribuiamo a un'ipotesi alla luce di nuove evidenze, via via che vengono raccolte, in modo tale da formulare un'ipotesi a posteriori che può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo di aggiornamento del grado di fiducia è noto come *aggiornamento bayesiano*.\n",
    "\n",
    "## Esercizio di ricapitolazione con Python\n",
    "\n",
    "Proseguendo con l'esempio del capitolo precedente, usiamo i dati `penguins` per applicare il teorema di Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333 entries, 0 to 343\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            333 non-null    object \n",
      " 1   island             333 non-null    object \n",
      " 2   bill_length_mm     333 non-null    float64\n",
      " 3   bill_depth_mm      333 non-null    float64\n",
      " 4   flipper_length_mm  333 non-null    float64\n",
      " 5   body_mass_g        333 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      " 7   year               333 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/penguins.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riprendiamo le funzioni `prob` e `conditional` che abbiamo definito in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(A):\n",
    "    \"\"\"Computes the probability of a proposition, A.\"\"\" \n",
    "    return A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(proposition, given): \n",
    "    return prob(proposition[given])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la congiunzione vale la proprietà di commutatività:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = df[\"sex\"] == \"female\"\n",
    "small = df[\"body_mass_g\"] < df[\"body_mass_g\"].quantile(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob(female & small) == prob(small & female)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi possiamo scrivere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2552552552552553"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional(female, given=small) * prob(small) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oppure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2552552552552552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional(small, given=female) * prob(female) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giungiamo così al teorema di Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8252427184466019"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional(female, given=small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8252427184466018"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional(small, given=female) * prob(female) / prob(small)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oppure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional(small, given=female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151515151515152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional(female, given=small) * prob(small) / prob(female)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Il problema delle due urne\n",
    "Supponiamo che vi siano due urne.\n",
    "\n",
    "- L'urna 1 ($U_1$) contiene 30 palline bianche (B) e 10 palline nere (N).\n",
    "- L'urna 2 ($U_2$) contiene 20 palline bianche e 20 palline nere.\n",
    "\n",
    "Supponiamo di scegliere una delle urne a caso e, senza guardare, di scegliere una pallina a caso. Se la pallina è bianca, qual è la probabilità che provenga dall'urna 1?\n",
    "\n",
    "Quello che vogliamo è la probabilità condizionata che abbiamo scelto dall'Urna 1 dato che abbiamo ottenuto una pallina bianca, $P(U_1 \\mid B)$.\n",
    "\n",
    "Il problema ci fornisce le seguenti informazioni:\n",
    "\n",
    "- $P(B \\mid U_1)$ = 3/4,\n",
    "- $P(B \\mid U_2)$ = 1/2.\n",
    "\n",
    "Il teorema di Bayes ci dice come le informazioni a disposizione si possono mettere in relazione con la domanda del problema:\n",
    "\n",
    "$$\n",
    "P(U_1 \\mid B) = \\frac{P(B \\mid U_1) P(U_1)}{P(B)}\n",
    "$$\n",
    "\n",
    "Per calcolare la probabilità $P(B)$ usiamo il teorema della probabilità totale:\n",
    "\n",
    "$$\n",
    "P(B) = P(B \\mid U_1) P(U_1) + P(B \\mid U_2) P(U_2),\n",
    "$$\n",
    "\n",
    "ovvero\n",
    "\n",
    "$$\n",
    "P(B) = 3/4 \\cdot 1/2 + 1/2 \\cdot 1/2 = 5/8.\n",
    "$$\n",
    "\n",
    "Concludiamo applicando il teorema di Bayes:\n",
    "\n",
    "$$\n",
    "P(U_1 \\mid B) = \\frac{3/4 \\cdot 1/2}{5/8} = 3/5.\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il processo di aggiornamento bayesiano può essere anche svolto nel modo seguente. Riscrivo il teorema di Bayes nel modo seguente:\n",
    "\n",
    "$$\n",
    "P(H \\mid D) = \\frac{P(D \\mid H) P(H)}{P(D)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilità $P(H)$ è la probabilità delle ipotesi prima di avere osservato i dati. Nel nostro caso, le due ipotesi sono \"Urna 1\" e \"Urna 2\", entrambe con la stessa probabilità, dato che non abbiamo ragioni a priori per dare più peso ad un'ipotesi rispetto all'altra. Costruiamo una tabella con un DataFrame in cui inseriamo la colonna `prior`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Urn 1</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urn 2</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prior\n",
       "Urn 1    0.5\n",
       "Urn 2    0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(index=['Urn 1', 'Urn 2'])\n",
    "table['prior'] = 1/2, 1/2\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilità $P(D \\mid H)$ è la probabilità dei dati, data l'ipotesi. È chiamata verosimiglianza. La probabilità di una pallina bianca dato che viene estratta dall'Urna 1 è 3/4. La probabilità di una pallina bianca dato che viene estratta dall'Urna 1 è 1/2. Aggiungo alla tabella la colonna `likelihood`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Urn 1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urn 2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prior  likelihood\n",
       "Urn 1    0.5        0.75\n",
       "Urn 2    0.5        0.50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['likelihood'] = 3/4, 1/2\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilità $P(H \\mid D)$ è la probabilità dell'ipotesi dopo avere osservato i dati. Si ottiene come il prodotto della verosimiglianza per la probabilità a priori, diviso per una *costante di normalizzazione*. Iniziamo a calcolare il la distribuzione a posteriori non normalizzata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Urn 1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urn 2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prior  likelihood  unnorm\n",
       "Urn 1    0.5        0.75   0.375\n",
       "Urn 2    0.5        0.50   0.250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilità dei dati, $P(D)$, ovvero il numeratore bayesiano, è dato dalla somma di tutti i valori della distribuzione a posteriori non normalizzata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_data = table['unnorm'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo ora normalizzare la distribuzione a posteriori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Urn 1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urn 2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prior  likelihood  unnorm  posterior\n",
       "Urn 1    0.5        0.75   0.375        0.6\n",
       "Urn 2    0.5        0.50   0.250        0.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "table['posterior'] = table['unnorm'] / prob_data\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Il problema dei dadi\n",
    "Il metodo precedente può anche essere usato quando ci sono più di due ipotesi. {cite:t}`downey2021think` discute il seguente problema. Supponiamo che nell'Urna 1 ci sia un dado a 6 facce, nell'Urna 2 un dado a 8 facce e nell'Urna 3 un dado a 12 facce. Un dado viene estratto a caso da un'urna e produce il risultato 1. Qual è la probabilità che ho usato un dado a 6 facce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [6, 8, 12]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2 = pd.DataFrame(index=[6, 8, 12])\n",
    "table2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare arrotondamenti uso la funzione `Fraction()`. Inizio a definire la distribuzione a priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior likelihood\n",
       "6    1/3        1/6\n",
       "8    1/3        1/8\n",
       "12   1/3       1/12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "table2['prior'] = Fraction(1, 3)\n",
    "table2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisco la verosimiglianza. Se il dado è a 6 facce, la probabilità di ottenere 1 è 1/6; se il dado ha 8 facce è 1/8; se il dado ha 12 facce è 1/12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior likelihood\n",
       "6    1/3        1/6\n",
       "8    1/3        1/8\n",
       "12   1/3       1/12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2['likelihood'] = Fraction(1, 6), Fraction(1, 8), Fraction(1, 12)\n",
    "table2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trovo la distribuzione a posteriori non normalizzata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/6</td>\n",
       "      <td>1/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/8</td>\n",
       "      <td>1/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/12</td>\n",
       "      <td>1/36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior likelihood unnorm\n",
       "6    1/3        1/6   1/18\n",
       "8    1/3        1/8   1/24\n",
       "12   1/3       1/12   1/36"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2['unnorm'] = table2['prior'] * table2['likelihood']\n",
    "table2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/6</td>\n",
       "      <td>1/18</td>\n",
       "      <td>4/9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/8</td>\n",
       "      <td>1/24</td>\n",
       "      <td>1/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/3</td>\n",
       "      <td>1/12</td>\n",
       "      <td>1/36</td>\n",
       "      <td>2/9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior likelihood unnorm posterior\n",
       "6    1/3        1/6   1/18       4/9\n",
       "8    1/3        1/8   1/24       1/3\n",
       "12   1/3       1/12   1/36       2/9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_data = table2['unnorm'].sum()\n",
    "table2['posterior'] = table2['unnorm'] / prob_data\n",
    "table2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilità posteriore del dado a 6 facce è 4/9, che è più grande delle probabilità degli altri dadi, 3/9 e 2/9. Intuitivamente, il dado a 6 facce è il più probabile perché ha la probabilità più grande di produrre il risultato che abbiamo osservato."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commenti e considerazioni finali\n",
    "\n",
    "La riflessione epistemologica moderna ha dimostrato che la conoscenza non può essere ridotta alla certezza o alla garanzia razionale della verità. Pertanto, ogni giudizio deve essere considerato come una decisione presa in condizioni di incertezza. In questo contesto, la logica deduttiva, che si basa sulle forme della dimostrazione matematica, non è più sufficiente per il ragionamento scientifico. La ricerca scientifica richiede invece una \"logica dell'incertezza\", fornita dalla teoria delle probabilità e in particolare dal teorema di Bayes. È proprio in quest'ottica che si può comprendere la rivoluzione metodologica contemporanea che cerca di risolvere la crisi della replicabilità dei risultati della ricerca {cite:p}`ioannidis2005most`, che sta affliggendo molti campi, tra cui la psicologia. Per approfondire questo tema, si può consultare il libro \"Bernoulli's Fallacy\" di {cite:t}`clayton2021bernoulli`.\n",
    "\n",
    "In questo capitolo abbiamo presentato il teorema di Bayes utilizzando variabili casuali discrete. Tuttavia, il caso discreto, nonostante la sua semplicità matematica, è il più controintuitivo. Risulta più intuitivo applicare il teorema di Bayes alle variabili casuali continue. Questo aspetto sarà trattato nel capitolo successivo {ref}`bayes-workflow-notebook`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbb367cc0128e23b7454d788d5a4229ca1f9848fd2e857f4797fbd26ab3b0776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
